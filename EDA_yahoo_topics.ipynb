{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY1RXvKU59Ei"
      },
      "source": [
        "# And now for something completely different..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrYtljvE59Ek"
      },
      "source": [
        "## EDA on a Hugging Face dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnwuFk8S59Ek"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall -y umap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIOi9MVG59El"
      },
      "outputs": [],
      "source": [
        "!pip install \"transformers[torch]\" datasets scikit-learn umap-learn pandas numpy matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94nbC_4H59El"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datasets\n",
        "\n",
        "pd.set_option('max_colwidth', 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHpVtAcc59Em"
      },
      "source": [
        "### Choose dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufnYXtFg59Em"
      },
      "outputs": [],
      "source": [
        "# datasets.list_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh565PS459Em"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "pprint.pprint(datasets.get_dataset_config_info('yahoo_answers_topics'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71_-Q1LR59En"
      },
      "outputs": [],
      "source": [
        "builder = datasets.load_dataset_builder('yahoo_answers_topics')\n",
        "print(f\"size of dataset: {round(builder.info.dataset_size/2**30, 2)} GB\") # ~0.74 GB\n",
        "print(f\"size of download: {round(builder.info.download_size/2**30, 2)} GB\") # ~0.3 GB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tJl4hC659En"
      },
      "outputs": [],
      "source": [
        "qa10topics = datasets.load_dataset('yahoo_answers_topics')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6r0HVep59En"
      },
      "source": [
        "### Check out DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcF-2a9H59En"
      },
      "outputs": [],
      "source": [
        "qa10topics # huge: 1.4 million training examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQpZlZsp59Eo"
      },
      "outputs": [],
      "source": [
        "qa10topics['train'].column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKU6aAID59Eo"
      },
      "outputs": [],
      "source": [
        "qa10topics['train'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1tnXQeX59Eo"
      },
      "outputs": [],
      "source": [
        "labels = qa10topics['train'].features['topic'].names\n",
        "labels # this dataset is annotated more for classification than QA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B66PO0zd59Eo"
      },
      "outputs": [],
      "source": [
        "qa10topics.set_format('pandas')\n",
        "qa10topics['train'][0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrWcHyIW59Eo"
      },
      "outputs": [],
      "source": [
        "# Ditch the test split and the question_content column\n",
        "qa10topics = None\n",
        "qa10topics = datasets.load_dataset(\"yahoo_answers_topics\", split=\"train\")\n",
        "qa10topics = qa10topics.remove_columns('question_content')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InZAHkmF59Ep"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0GtD6yY59Ep"
      },
      "source": [
        "### Closer look at training split, as pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-aU0S7z59Ep"
      },
      "outputs": [],
      "source": [
        "df = qa10topics.to_pandas() # could use batch size to avoid memory issues\n",
        "df['topic_name'] = df['topic'].apply(lambda x: labels[x]) # readable labels\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFrNo2eP59Ep"
      },
      "outputs": [],
      "source": [
        "df['topic'].value_counts() # balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vhKOenC59Ep"
      },
      "outputs": [],
      "source": [
        "df.info() # no nulls in any column (but later we will notice blanks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXeCMcNl59Ep"
      },
      "outputs": [],
      "source": [
        "df.id.nunique() # 'id' is indeed unique id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuVYkQIO59Ep"
      },
      "outputs": [],
      "source": [
        "df.groupby(['topic_name'])['id'].describe() # id independent of topic -- topics scattered, not blocked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUfFYUpr59Ep"
      },
      "outputs": [],
      "source": [
        "df[\"question_title\"].apply(lambda x: len(x.split())).min() # shortest question titles?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfsQv54y59Eq"
      },
      "outputs": [],
      "source": [
        "df[df[\"question_title\"].apply(lambda x: len(x.split())==1)] # One-word questions coincide with heavy repetition on '?'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrEI37I659Eq"
      },
      "outputs": [],
      "source": [
        "df[\"best_answer\"].apply(lambda x: len(x.split())).min() # Most concise answers?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixBesnBW59Eq"
      },
      "outputs": [],
      "source": [
        "df[df[\"best_answer\"].apply(lambda x: len(x.split()))==0] # A lot of these answers appear blank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YbcqOqV59Eq"
      },
      "outputs": [],
      "source": [
        "df.query(\"best_answer == ''\") # 24,572 rows with blank answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17Vl9wh759Eq"
      },
      "outputs": [],
      "source": [
        "df.query(\"best_answer == ''\").groupby(['topic_name'])['id'].count().plot(\n",
        "    kind='bar', title='Unanswered questions, by topic')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVChp-2F59Eq"
      },
      "source": [
        "### Filter out blank answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Sncey6559Eq"
      },
      "outputs": [],
      "source": [
        "pattern = re.compile('^\\s*$') # blanks\n",
        "\n",
        "# if using huggingface dataset, ...\n",
        "# ds.filter(lambda x: len(pattern.findall(x[\"best_answer\"])) == 0)\n",
        "\n",
        "df = df[~df['best_answer'].str.match(pattern)] # drop blanks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bfTz3wu59Eq"
      },
      "source": [
        "Re-examine topic counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRRhwIW159Eq"
      },
      "outputs": [],
      "source": [
        "df['topic_name'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE8LnElG59Eq"
      },
      "source": [
        "Topics remain well balanced, huge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmyqEWk659Er"
      },
      "outputs": [],
      "source": [
        "df['topic_name'].value_counts().plot(kind='barh', title='Topic counts')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxyWo1cl59Er"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5MHpbZ859Er"
      },
      "source": [
        "### Clean and split for word counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P31nLSSr59Er"
      },
      "outputs": [],
      "source": [
        "def cleaner(text):\n",
        "    text = re.sub('<.{,10}>', ' ', text) # remove some html tags\n",
        "    text = text.replace(\"'\", '') # remove apostrophes\n",
        "    text = re.sub('[^A-Za-z ]', ' ', text) # if punctuation matters, use re.sub(f'[^{string.printable}]', ' ', text)\n",
        "    text = re.sub(' {2,}', ' ', text) # remove extra spaces\n",
        "    text = text.lower().strip().split()\n",
        "    return text\n",
        "\n",
        "s = \" hear that the mojave road is amazing!<br />\\.. \"\n",
        "cleaner(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lnXPvOF59Ew"
      },
      "outputs": [],
      "source": [
        "df = df.assign(question_title = df[\"question_title\"].apply(cleaner))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQeHQP0E59Ew"
      },
      "outputs": [],
      "source": [
        "df = df.assign(best_answer = df[\"best_answer\"].apply(cleaner))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTI7ZLgU59Ew"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAW-EM2t59Ew"
      },
      "source": [
        "### How do questions begin?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1trGxQo59Ew"
      },
      "outputs": [],
      "source": [
        "# new column for question start word\n",
        "df['q_start'] = df['question_title'].apply(lambda x: x[0] if len(x)>0 else '') \n",
        "\n",
        "# within each topic, what are the most frequent question start words?\n",
        "q_start_freq = df.groupby(['topic_name']).value_counts(['q_start'])\n",
        "\n",
        "# check out top couple in each topic\n",
        "q_start_freq.groupby(['topic_name']).nlargest(2).droplevel(level=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYNv-QiS59Ew"
      },
      "source": [
        "- It seems that \"who\" is more common in Sports & Entertainment,\n",
        "- while \"why\" is more common in Politics & Society.\n",
        "- \"how\" dominates Computers & Internet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZuEE3g-59Ew"
      },
      "outputs": [],
      "source": [
        "q_df = pd.DataFrame()\n",
        "for topic in labels:\n",
        "    q_df[topic] = q_start_freq.loc[topic].index[:10]\n",
        "q_df # most topics have same q_start words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDBWJqhg59Ex"
      },
      "source": [
        "Let's see it with the q_start words aligned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4SSEDPL59Ex"
      },
      "outputs": [],
      "source": [
        "top_question_starts = set(q_df.values.flatten()) # <- union of words in 10x10 q_df above\n",
        "q_viz = q_start_freq.to_frame(name=\"count\").query(\"q_start in @top_question_starts\") # filter df to 15 words that capture all topics' top 10\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title('Most common question starts, by topic')\n",
        "sns.heatmap(q_viz.reset_index().pivot(index='topic_name', columns='q_start', values='count'), \n",
        "            cmap='Blues', square=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaV_y6kr59Ex"
      },
      "source": [
        "- Why do so many questions start with \"I\"? \n",
        "- especially in health, family, computers \n",
        "- Framing the question with challenge or desire? \"I want to know...?\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6aE63-G59Ex"
      },
      "outputs": [],
      "source": [
        "df.query(\"q_start == 'i'\")[:3] # yeah, framing the question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V1ujAyR59Ex"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=[\"q_start\"], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJVzvz8n59Ex"
      },
      "source": [
        "### Word counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s0n-xcx59Ex"
      },
      "outputs": [],
      "source": [
        "df['nwords_q'] = df[\"question_title\"].apply(lambda x: len(x))\n",
        "df['nwords_a'] = df[\"best_answer\"].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI6WFuu_59Ex"
      },
      "outputs": [],
      "source": [
        "df[['nwords_q', 'nwords_a']].describe().astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sHE8rWo59Ex"
      },
      "source": [
        "- We removed blanks earlier, but that was before cleaning and splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRjwSEEC59Ex"
      },
      "outputs": [],
      "source": [
        "df = df[df.nwords_q.apply(lambda x: x>0)] \n",
        "df = df[df.nwords_a.apply(lambda x: x>0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns8OjOjI59Ex"
      },
      "outputs": [],
      "source": [
        "df[['nwords_q', 'nwords_a']].describe().astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLryYua059Ey"
      },
      "source": [
        "- Ok, no more blanks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hWyfoeD59Ey"
      },
      "outputs": [],
      "source": [
        "df['nwords_q'].plot(kind='hist', bins=20, title='Most questions have 5-15 words', xlabel='Number of words in question')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vysLFUB359Ey"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.title('Many short answers, gamma distribution')\n",
        "plt.xlabel('Number of words in answer')\n",
        "plt.ylabel('Frequency')\n",
        "plt.hist(df['nwords_a'], bins=200, range=(0, 150), histtype='bar', rwidth=2)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjpY6rzQ59Ey"
      },
      "source": [
        "### if time permits, topic modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIMadQjo59Ey"
      },
      "source": [
        "start with stop-word removal "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ncn9J_vL59Ey"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "cum_tallies = Counter()\n",
        "\n",
        "for words in df['question_title'].values:\n",
        "    cum_tallies.update(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3zbR-fH59Ey"
      },
      "outputs": [],
      "source": [
        "cum_tallies.most_common(100) # top 100 all look generic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm7Yyh5d59Ey"
      },
      "outputs": [],
      "source": [
        "stops = {tup[0] for tup in cum_tallies.most_common(100)}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-4GSUfC59Ey"
      },
      "source": [
        "...nope, no topic modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uzLMuEU59Ey"
      },
      "source": [
        "if time permitted, I might list some common Spanish words, French words, etc., then remove examples with high counts of foreign stop words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDfyuLfJ59Ey"
      },
      "source": [
        "___\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sdCajDM59Ey"
      },
      "source": [
        "## Restart kernel with GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJPy2CQ759Ey"
      },
      "source": [
        "### get encodings, embeddings, for umap visualization of small batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPjtr-Jp59Ey"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "import datasets\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WgnfTCd59Ez"
      },
      "source": [
        "Load a tokenizer and pre-trained (headless) model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1bqiNlv59Ez"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "chkpt = \"deepset/roberta-base-squad2-distilled\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(chkpt)\n",
        "model = AutoModel.from_pretrained(chkpt).to(device)\n",
        "\n",
        "tokenizer.vocab_size, tokenizer.model_max_length, tokenizer.model_input_names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "qlxJuNczCnVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSJsLStB59Ez"
      },
      "outputs": [],
      "source": [
        "# # if Dataset instead of IterableDataset \n",
        "# from torch.utils.data import DataLoader\n",
        "# qa10topics.set_format(type=\"torch\")\n",
        "# training_dataloader = DataLoader(qa10topics['train'], batch_size=batch_size)\n",
        "# batch = next(iter(training_dataloader))\n",
        "# batch.update(tokenize(batch))\n",
        "# batch.update(extract_hidden_states(batch))\n",
        "# batch['feature_embeddings'].shape # (1, 768)\n",
        "# X_train = np.array(batch[\"feature_embeddings\"])\n",
        "# y_train = np.array(batch[\"topic\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSDuAs0m59Ez"
      },
      "source": [
        "Prepare an IterableDataset to take small batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 100"
      ],
      "metadata": {
        "id": "EqCQUTIJ6-a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52O2O4rf59Ez"
      },
      "outputs": [],
      "source": [
        "ds = datasets.load_dataset(\"yahoo_answers_topics\", split=\"train\", streaming=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZs64oNs59Ez"
      },
      "outputs": [],
      "source": [
        "ds = ds.remove_columns('question_content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B3Camsf59Ez"
      },
      "outputs": [],
      "source": [
        "# avoid blanks\n",
        "pattern = re.compile('^\\s*$')\n",
        "ds = ds.filter(lambda x: len(pattern.findall(x[\"best_answer\"])) == 0)\n",
        "ds = ds.filter(lambda x: len(pattern.findall(x[\"question_title\"])) == 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU0SrYdd59Ez"
      },
      "outputs": [],
      "source": [
        "shuffled_ds = ds.shuffle(seed=8, buffer_size=BUFFER_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIdkKGdV59Ez"
      },
      "source": [
        "NB: any function mapped to IterableDataset much accept and return a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5FMj_8s59Ez"
      },
      "outputs": [],
      "source": [
        "def tokenize(batch: dict)-> dict:\n",
        "    \"\"\"\n",
        "    Even though this dataset isn't annotated for extractive QA \n",
        "    and the distilled RoBERTa tokenizer doesn't require (Q,A) input, \n",
        "    I'll tokenize QA pair, just for fun; maybe later we will decide to try \n",
        "    a QA pipeline with metadata fields to limit the retriever.\n",
        "    \"\"\"\n",
        "    return tokenizer(batch[\"question_title\"], batch[\"best_answer\"], padding='max_length', truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkxfPlYc59Ez"
      },
      "outputs": [],
      "source": [
        "def extract_hidden_states(batch: dict)-> dict:\n",
        "    \"\"\" get feature embeddings from headless model \"\"\"\n",
        "\n",
        "    inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
        "\n",
        "    with torch.no_grad():# qa10topics.set_format(type=\"torch\")\n",
        "        last_hidden_state = model(**inputs).last_hidden_state\n",
        "\n",
        "    return {\"feature_embeddings\": last_hidden_state[:,0].cpu().numpy()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK8E8n0v59Ez"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(shuffled_ds, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {
        "id": "dNS3NmZZEXmY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZkPUMVC59E0"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2CxPwcE59E0"
      },
      "outputs": [],
      "source": [
        "batch.update(tokenize(batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAMlVyqs59E0"
      },
      "outputs": [],
      "source": [
        "batch.update(extract_hidden_states(batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euMr5zV559E0"
      },
      "outputs": [],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z01SfBVd59E0"
      },
      "outputs": [],
      "source": [
        "batch['feature_embeddings'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRLZFJT159E0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from umap import UMAP\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFyy6Sz759E0"
      },
      "outputs": [],
      "source": [
        "X_train = batch[\"feature_embeddings\"]\n",
        "y_train = batch[\"topic\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzuXDlaV59E0"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_train) # scale to [0,1], for umap dimension reduction algo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0x9dfn059E0"
      },
      "outputs": [],
      "source": [
        "mapper = UMAP(n_components=2, metric=\"cosine\").fit(X_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCx2fMGf59E0"
      },
      "source": [
        "Get readable labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bByYH4Rb59E0"
      },
      "outputs": [],
      "source": [
        "builder = datasets.load_dataset_builder(\"yahoo_answers_topics\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DVRHb3H59E0"
      },
      "outputs": [],
      "source": [
        "labels = builder.info.features['topic'].names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcliVAKE59E0"
      },
      "source": [
        "Dataframe for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-B3orZZ59E0"
      },
      "outputs": [],
      "source": [
        "df_embed = pd.DataFrame(mapper.embedding_, columns=[\"X\",\"y\"])\n",
        "df_embed[\"label\"] = y_train\n",
        "df_embed.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15DNOK5859E1"
      },
      "source": [
        "From Hugging Face book:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAZuMfvE59E1"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 5, figsize=(12,5))\n",
        "axes = axes.flatten()\n",
        "cmaps = [\"Greys\", \"Blues\", \"Oranges\", \"Reds\", \"Purples\", \n",
        "         \"Greens\", \"PuRd\", \"YlOrBr\", \"YlGnBu\", \"RdPu\"]\n",
        "\n",
        "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
        "    df_emb_sub = df_embed.query(f\"label == {i}\")\n",
        "    axes[i].hexbin(df_emb_sub[\"X\"], df_emb_sub[\"y\"], cmap=cmap,\n",
        "                   gridsize=20, linewidths=(0,))\n",
        "    axes[i].set_title(label)\n",
        "    axes[i].set_xticks([]), axes[i].set_yticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show() # not perfect, but sufficient for a sanity-check: patterns are consistent within-topic batch after batch, but not identical across topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqEfWUeX59E1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSsKVDBk59E1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdcIZwP759E1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSbTtkLB59E1"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRh8852s59E1"
      },
      "source": [
        "note to self: to save intermediate dataset to cloud storage -- more generally, to use huggingface or tensorflow or keras methods that expect a filesystem (like datagenfromdirectory) -- use FUSE, or gcsfs:\n",
        "<https://huggingface.co/docs/datasets/v1.11.0/filesystems.html>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gcsfs\n",
        "# import gcsfs\n",
        "# gcs = gcsfs.GCSFileSystem(project=\"gcs_project_name\")\n",
        "# encoded_dataset.save_to_disk(\"gcs://bucket_name/enc_ds\", fs=gcs)"
      ],
      "metadata": {
        "id": "Gu-iu7M1H3A2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}